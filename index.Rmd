---
title: 'Machine Learning project: predicting correctness of movement'
author: "Loren Serfass"
date: "01/17/2015"
output:
    html_document:
        toc: true
---

```{r message=F, echo=F}
library(ggplot2)
library(caret)
```

## Load data

```{r}
pml.train.val <- read.csv('data/pml-training.csv', na.strings=c("","NA") )  # training and validation sets
pml.test <- read.csv('data/pml-testing.csv', na.strings=c("","NA"))         # 20 test observations
pml.train.val <- pml.train.val[,-1] # first column of file is row numbers
pml.test <- pml.test[,-1]           # first column of file is row numbers
```

## Structure of the dataset

The result variable is `classe`, a factor variable containing A, B, C, D, and E.

I will not use the timestamp variables in my model: I take it that we are
meant to be able to distinguish the motions regardless of when they occured.
The `num_window` variable will not be used in the model, but will be used
to aggregate the data per window, with the main purpose of making a smaller
dataset.

```{r}
pml.train.val <- pml.train.val[,-(2:5)] # remove timestamp columns
```

The model will include only `user_name` and the following 52 variables (in black text):

<table border=1>
<tr><td><font color='red'></font></td><td><font color='red'>belt</font></td><td><font color='red'>arm</font></td><td><font color='red'>dumbbell</font></td><td><font color='red'>forearm</font></td></tr>
<tr><td><font color='red'>roll</font></td><td>roll_belt</td><td>roll_arm</td><td>roll_dumbbell</td><td>roll_forearm</td></tr>
<tr><td><font color='red'>pitch</font></td><td>pitch_belt</td><td>pitch_arm</td><td>pitch_dumbbell</td><td>pitch_forearm</td></tr>
<tr><td><font color='red'>yaw</font></td><td>yaw_belt</td><td>yaw_arm</td><td>yaw_dumbbell</td><td>yaw_forearm</td></tr>
<tr><td><font color='red'>total_accel</font></td><td>total_accel_belt</td><td>total_accel_arm</td><td>total_accel_dumbbell</td><td>total_accel_forearm</td></tr>
<tr><td><font color='red'>gyros_x</font></td><td>gyros_x_belt</td><td>gyros_x_arm</td><td>gyros_x_dumbbell</td><td>gyros_x_forearm</td></tr>
<tr><td><font color='red'>gyros_y</font></td><td>gyros_y_belt</td><td>gyros_y_arm</td><td>gyros_y_dumbbell</td><td>gyros_y_forearm</td></tr>
<tr><td><font color='red'>gyros_z</font></td><td>gyros_z_belt</td><td>gyros_z_arm</td><td>gyros_z_dumbbell</td><td>gyros_z_forearm</td></tr>
<tr><td><font color='red'>accel_x</font></td><td>accel_x_belt</td><td>accel_x_arm</td><td>accel_x_dumbbell</td><td>accel_x_forearm</td></tr>
<tr><td><font color='red'>accel_y</font></td><td>accel_y_belt</td><td>accel_y_arm</td><td>accel_y_dumbbell</td><td>accel_y_forearm</td></tr>
<tr><td><font color='red'>accel_z</font></td><td>accel_z_belt</td><td>accel_z_arm</td><td>accel_z_dumbbell</td><td>accel_z_forearm</td></tr>
<tr><td><font color='red'>magnet_x</font></td><td>magnet_x_belt</td><td>magnet_x_arm</td><td>magnet_x_dumbbell</td><td>magnet_x_forearm</td></tr>
<tr><td><font color='red'>magnet_y</font></td><td>magnet_y_belt</td><td>magnet_y_arm</td><td>magnet_y_dumbbell</td><td>magnet_y_forearm</td></tr>
<tr><td><font color='red'>magnet_z</font></td><td>magnet_z_belt</td><td>magnet_z_arm</td><td>magnet_z_dumbbell</td><td>magnet_z_forearm</td></tr>
</table>

<br/>
**Note:** The model won't include [the remaining 100 columns](UnusedVariables.html),
They are "summary" columns which are blank in the training set
except for rows in which `new_window` is 'yes'. They are also blank in the test set.

The following code removes the extra columns from the training set:

```{r message=F}
require(plyr)
count.NA <- unlist(colwise(function(x) {sum(is.na(x))})(pml.train.val)) # count NAs in each column
table(count.NA) # There are full columns and mostly-empty columns.
pml.train.val <- pml.train.val[,count.NA == 0] # removes the summary columns
```

<<<<<<< HEAD:Project.Rmd
The [paper](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf) hints that per-window means are the most
helpful predictors. This code constructs a much smaller dataset with
the per-window column means.
=======
The [paper](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf) 
hints that per-window means are the most
helpful predictors.  This code constructs a much smaller dataset with
the per-window column means:
>>>>>>> gh-pages:index.Rmd

```{r}
mean.pml.train.val <- aggregate(pml.train.val[,-c(1,2,55)],
                                by=list(pml.train.val$user_name,
                                        pml.train.val$num_window,
                                        pml.train.val$classe),
                                FUN=mean)
names(mean.pml.train.val)[1:3] <- c('user_name', 'num_window', 'classe')
```

## Model building
<<<<<<< HEAD:Project.Rmd
=======

Following the hint in the paper, I used a random forest. Training a random
forest on `pml.train.val` took more than 20 minutes on my computer (I stopped
it).  Instead I divided `mean.pml.train.val` into `training` and `validation`,
and trained the model on `training`.

The `caret` defaults resulted in about 83% accuracy when predicting on
observations in `pml.train.val`, from windows not used `training`.
>>>>>>> gh-pages:index.Rmd

```{r}
set.seed(8732) # typed by my cat
inTrain <- createDataPartition(mean.pml.train.val$classe, p=.80, list=F)
training <- mean.pml.train.val[inTrain,]
validation <- mean.pml.train.val[-inTrain,]
rf.model <- train(classe ~ . - num_window, data=training, method='rf')
```

Testing prediction on the validation set (`pml.train.val`, using only rows
from windows not used in `training`):

```{r}
allowed <- pml.train.val$num_window %in% validation$num_window
pred <- predict(rf.model, pml.train.val[allowed,])
```

Confusion matrix for predictions on validation set:

```{r}
table(pred, pml.train.val$classe[allowed])
```

Validation set accuracy:

```{r}
sum(pred == pml.train.val$classe[allowed]) / sum(allowed)
```

Finally, predictions on the test set:

```{r}
predict(rf.model, pml.test)
```

